{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awswrangler\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9d/ab160a0857e80ab143f4a81abb5fa28b1a325ec8f660fd2a0ac455924247/awswrangler-0.0.25.tar.gz (44kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 23.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting numpy~=1.17.4 (from awswrangler)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.0MB 2.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas~=0.25.3 (from awswrangler)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyarrow~=0.15.1 (from awswrangler)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/77/5865b367a6792da2f811ae49391c1f85c29b29663555aac0a118fe8e153e/pyarrow-0.15.1-cp36-cp36m-manylinux1_x86_64.whl (59.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 59.0MB 824kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting botocore~=1.13.25 (from awswrangler)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/69/abe9276bc3699aa89cd5f743982aa9d9ce929d7f95b4900bba60922747b0/botocore-1.13.35-py2.py3-none-any.whl (5.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.8MB 11.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting boto3~=1.10.25 (from awswrangler)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/f7/45cb1f72e7824d2b16b5232b914c8a4f490ae83db569f28023a1ebdea52c/boto3-1.10.35-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 42.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting s3fs~=0.4.0 (from awswrangler)\n",
      "  Downloading https://files.pythonhosted.org/packages/72/5c/ec84c7ec49fde2c3b0d885ecae4504fa40fc77fef7684e9f2939c50f9b94/s3fs-0.4.0-py3-none-any.whl\n",
      "Collecting tenacity~=6.0.0 (from awswrangler)\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/d4/8cab4b5239ddb62d950243abff9e88046bb61737ce3eee8694b3d748560c/tenacity-6.0.0-py2.py3-none-any.whl\n",
      "Collecting pg8000~=1.13.2 (from awswrangler)\n",
      "  Downloading https://files.pythonhosted.org/packages/16/32/ae895597e43bc968e0e3e63860e9932b851115457face0d06d7f451b71fc/pg8000-1.13.2-py3-none-any.whl\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas~=0.25.3->awswrangler) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas~=0.25.3->awswrangler) (2.7.3)\n",
      "Requirement already satisfied: six>=1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyarrow~=0.15.1->awswrangler) (1.11.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore~=1.13.25->awswrangler) (0.9.4)\n",
      "Requirement already satisfied: urllib3<1.26,>=1.20; python_version >= \"3.4\" in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore~=1.13.25->awswrangler) (1.23)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore~=1.13.25->awswrangler) (0.14)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3~=1.10.25->awswrangler) (0.2.1)\n",
      "Collecting fsspec>=0.6.0 (from s3fs~=0.4.0->awswrangler)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/04/1e/6108c48f2d4ad9ef1a6bff01fb58245c009f37b2bd0505ec6d0f55cc326d/fsspec-0.6.1-py3-none-any.whl (62kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 35.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scramp==1.1.0 (from pg8000~=1.13.2->awswrangler)\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/ef/6bdba6756ba7ccb81187833504ebba0511af750a2d9beaa04e4b56c3974f/scramp-1.1.0-py3-none-any.whl\n",
      "Building wheels for collected packages: awswrangler\n",
      "  Running setup.py bdist_wheel for awswrangler ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/13/85/1f/8551f8da1490966be19563b9792aadfde46320cfd0d6e23633\n",
      "Successfully built awswrangler\n",
      "\u001b[31mawscli 1.16.283 has requirement botocore==1.13.19, but you'll have botocore 1.13.35 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy, pandas, pyarrow, botocore, boto3, fsspec, s3fs, tenacity, scramp, pg8000, awswrangler\n",
      "  Found existing installation: numpy 1.14.3\n",
      "    Uninstalling numpy-1.14.3:\n",
      "      Successfully uninstalled numpy-1.14.3\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "  Found existing installation: botocore 1.13.19\n",
      "    Uninstalling botocore-1.13.19:\n",
      "      Successfully uninstalled botocore-1.13.19\n",
      "  Found existing installation: boto3 1.10.19\n",
      "    Uninstalling boto3-1.10.19:\n",
      "      Successfully uninstalled boto3-1.10.19\n",
      "  Found existing installation: s3fs 0.1.5\n",
      "    Uninstalling s3fs-0.1.5:\n",
      "      Successfully uninstalled s3fs-0.1.5\n",
      "Successfully installed awswrangler-0.0.25 boto3-1.10.35 botocore-1.13.35 fsspec-0.6.1 numpy-1.17.4 pandas-0.25.3 pg8000-1.13.2 pyarrow-0.15.1 s3fs-0.4.0 scramp-1.1.0 tenacity-6.0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install awswrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Upload data to S3\n",
    "\n",
    "First you need to create a bucket for this experiment. Upload the data from the following public location to your own S3 bucket.\n",
    "\n",
    "You can create a bucket from the following link: <a href='https://s3.console.aws.amazon.com/s3/home?region=us-east-1'> s3 console </a>\n",
    "\n",
    "To facilitate the work of the crawler we will use two different prefixes (folders): one for the billing information and one for reseller. \n",
    "\n",
    "\n",
    "\n",
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your bucket name\n",
    "your_bucket = 'zoomagri-maxi-bucket-sagemaker'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-12-10 18:38:31--  https://ml-lab-mggaska.s3.amazonaws.com/billing_sm.csv\n",
      "Resolving ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)... 52.216.234.51\n",
      "Connecting to ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)|52.216.234.51|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15803443 (15M) [binary/octet-stream]\n",
      "Saving to: ‘billing_sm.csv’\n",
      "\n",
      "billing_sm.csv      100%[===================>]  15.07M  99.5MB/s    in 0.2s    \n",
      "\n",
      "2019-12-10 18:38:31 (99.5 MB/s) - ‘billing_sm.csv’ saved [15803443/15803443]\n",
      "\n",
      "--2019-12-10 18:38:31--  https://ml-lab-mggaska.s3.amazonaws.com/reseller_sm.csv\n",
      "Resolving ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)... 52.216.234.51\n",
      "Connecting to ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)|52.216.234.51|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 210111 (205K) [binary/octet-stream]\n",
      "Saving to: ‘reseller_sm.csv’\n",
      "\n",
      "reseller_sm.csv     100%[===================>] 205.19K  --.-KB/s    in 0.006s  \n",
      "\n",
      "2019-12-10 18:38:31 (31.1 MB/s) - ‘reseller_sm.csv’ saved [210111/210111]\n",
      "\n",
      "--2019-12-10 18:38:31--  https://ml-lab-mggaska.s3.amazonaws.com/awswrangler-0.0b2-py3.6.egg\n",
      "Resolving ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)... 52.216.234.51\n",
      "Connecting to ml-lab-mggaska.s3.amazonaws.com (ml-lab-mggaska.s3.amazonaws.com)|52.216.234.51|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 33511 (33K) [binary/octet-stream]\n",
      "Saving to: ‘awswrangler-0.0b2-py3.6.egg’\n",
      "\n",
      "awswrangler-0.0b2-p 100%[===================>]  32.73K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2019-12-10 18:38:31 (4.48 MB/s) - ‘awswrangler-0.0b2-py3.6.egg’ saved [33511/33511]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/billing_sm.csv\n",
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/reseller_sm.csv\n",
    "!wget https://ml-lab-mggaska.s3.amazonaws.com/awswrangler-0.0b2-py3.6.egg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, os\n",
    "import awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('billing', 'billing_sm.csv')).upload_file('billing_sm.csv')\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('reseller', 'reseller_sm.csv')).upload_file('reseller_sm.csv')\n",
    "boto3.Session().resource('s3').Bucket(your_bucket).Object(os.path.join('python', 'awswrangler-0.0b2-py3.6.egg')).upload_file('awswrangler-0.0b2-py3.6.egg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add athena full access permissions to SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::856165527696:role/service-role/AmazonSageMaker-ExecutionRole-20191210T152860\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the <a href='https://console.aws.amazon.com/iam/home?region=us-east-1#/roles'>IAM roles console</a> and attach the Amazon Athena full access policy to this role."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a Crawler\n",
    "\n",
    "To use this csv information in the context of a Glue ETL, first we have to create a Glue crawler pointing to the location of each file. The crawler will try to figure out the data types of each column. \n",
    "\n",
    "\n",
    "1. On the <a href='https://console.aws.amazon.com/iam/home?region=us-east-1#/roles'>IAM roles console</a> create an IAM role GlueCrawlerRole with the policy AWSGlueServiceRole and S3FullAccess.\n",
    "\n",
    "2. Go to  <a href='https://console.aws.amazon.com/glue/home?region=us-east-1#catalog:tab=crawlers'>Glue crawlers console</a> \n",
    "\n",
    "3. Add a Crawler : create one pointing to different each S3 locations (one to billing and one to reseller)\n",
    "\n",
    "    3.1 Fill  a Crawler Name: point a Data Store to specific S3 path, Navigate to your bucket and your folder: /billing, click \"Next\"\n",
    "    \n",
    "    3.2 Specify \"Yes\" to add a new Data Store and navigate to your bucket and your folder: /reseller, Click \"Next\" and select \"No\" when asking for add more Data stores, use an existing IAM role \"AWSGlueServiceRole\", add database \"implementationdb\", Click on \"Next\" and \"Finish\"\n",
    "    \n",
    "    3.3 After the crawler is created select \"Run it now\".\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Athena query destination\n",
    "\n",
    "Go to the <a href='https://console.aws.amazon.com/athena/home?force&region=us-east-1#query'>Athena console</a>.\n",
    "\n",
    "Under Settings in the top right corner set the query results location to s3://YOUR-BUCKET-NAME/athena-results/.\n",
    "\n",
    "To verify that your crawlers created correctly you can run the following query:\n",
    "    \n",
    "    select * from billing limit 3; \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Execute a query to create a sample View in Athena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "session = awswrangler.Session()\n",
    "query=('CREATE VIEW resellers_sample AS SELECT *'\n",
    "       'FROM billing where id_reseller '\n",
    "       'in (select distinct id_reseller from reseller TABLESAMPLE BERNOULLI(10))')\n",
    "\n",
    "df = session.pandas.read_sql_athena(\n",
    "    sql=query,\n",
    "    database=\"implementationdb\",\n",
    "    max_result_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Pandas._apply_dates_to_generator at 0x7fb1f6097048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
